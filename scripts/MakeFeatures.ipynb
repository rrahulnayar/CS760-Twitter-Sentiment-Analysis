{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataF = \"G:/edu/sem2/760/proj/CS760-Twitter-Sentiment-Analysis/data/\"\n",
    "allF = dataF+'train_utf8.csv'\n",
    "samF = dataF+'sample.csv'\n",
    "featF = dataF+'svmAllFeatures.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(samF)\n",
    "NUM_FEATURES = 7\n",
    "\n",
    "negWords = re.compile(\n",
    "    r'(not|no|nor|neither|(n\\'*t)|false|wrong)\\b'\n",
    ",re.I)\n",
    "\n",
    "posWords = re.compile(\n",
    "    r'yes|true|correct'\n",
    ",re.I)\n",
    "\n",
    "wasteWords =re.compile(\n",
    "    r'\\b(the|a|an|as|be|am|is|are|was|were|has|have|had|'+\n",
    "    r'at|from|to|in|under|before|after|near|far|away|for|and|'+\n",
    "    r'that|them|there|their|they|his|her|hers|him|it|you|your|yours)\\b'\n",
    ", re.I)\n",
    "\n",
    "#allow - &\n",
    "badpunc = re.compile(\n",
    "    r'\\.|\\_|\\:|\\'|\\`|\\\"|\\~|\\!|\\@|\\#|\\$|\\%|\\^|\\*|\\(|\\)|\\+|\\=|\\{|\\}|\\[|\\]|'+\n",
    "    r'\\;|\\<|\\>|\\,|\\?|\\/|\\\\|\\|')\n",
    "badwords = re.compile(r'\\b(fuck|(f\\*+))',re.I)\n",
    "\n",
    "#tweet character length\n",
    "def F0(txt):\n",
    "    return len(txt)\n",
    "\n",
    "#tweet word length\n",
    "def F1(txt):\n",
    "    return len(txt.split())\n",
    "\n",
    "#tweet character length w/o punc\n",
    "def F2(txt):\n",
    "    return len(re.sub(badpunc,'',txt))\n",
    "\n",
    "#word length w/o atricles and prepositions\n",
    "def F3(txt):\n",
    "    #print(re.sub(wasteWords,'',txt).split())\n",
    "    return len(re.sub(wasteWords,'',txt).split())\n",
    "\n",
    "#count of neg words\n",
    "def F4(txt):\n",
    "    return len(re.findall(negWords,txt))\n",
    "\n",
    "#count of pos words\n",
    "def F5(txt):\n",
    "    return len(re.findall(posWords,txt))\n",
    "#contains bad words\n",
    "def F6(txt):\n",
    "    #print(re.findall(badwords,txt))\n",
    "    return 1 if len(re.findall(badwords,txt))>0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#string corrections\n",
    "def modify(txt):\n",
    "    txt = txt.strip()\n",
    "    txt = txt.replace('&quot;',\"'\")\n",
    "    txt = txt.replace('&amp;','&')\n",
    "    txt = txt.replace('&lt;','<')\n",
    "    txt = txt.replace('&gt;','>')\n",
    "    txt = re.sub(r'\\s+',' ',txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = dt['Sentiment'].map(lambda x: 'Y' if x==1 else 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loop of features\n",
    "feats = {str(i):eval('F'+str(i)) for i in range(NUM_FEATURES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct all strings\n",
    "tweets = dt['SentimentText'].map(modify)\n",
    "tweets.to_csv('../data/tweetsModified.csv')\n",
    "#Build all features\n",
    "features = {i:tweets.map(f) for i,f in feats.items()}#ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize features\n",
    "ft = pd.concat(features,1)\n",
    "ft.to_csv('../data/features.csv')\n",
    "#Make Combined database\n",
    "normedFeats = pd.DataFrame(preprocessing.scale(ft))\n",
    "dataFrame = pd.DataFrame(labels)\n",
    "finalFeats = dataFrame.join(normedFeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to file for SVM learning\n",
    "finalFeats.to_csv(featF, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tw = \"@cpuclub what the hell mike died???? Fuck man I always played for that guy in denver. Such a generous and kind dude. Rip \"\n",
    "#tw = modify(tw)\n",
    "#print(tw,len(tw))\n",
    "#features = {i:f(tw) for i,f in feats.items()}#ma\n",
    "#print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
